{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yybXZPgXEu5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, a=0.1, b=2, c=1):\n",
        "    \"\"\"Combination of quadratic and sinusoidal function as the loss surface.\"\"\"\n",
        "    return a*x**2 + np.sin(b*x) + c\n"
      ],
      "metadata": {
        "id": "uJ9dI1RQExzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df(x, a=0.1, b=2):\n",
        "    \"\"\"Derivative of the combined function.\"\"\"\n",
        "    return 2*a*x + b*np.cos(b*x)"
      ],
      "metadata": {
        "id": "e3nOdW5sEzc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(initial_x, learning_rate, epochs, weight_decay=0):\n",
        "    \"\"\"Performs gradient descent on the combined function.\"\"\"\n",
        "    x = initial_x\n",
        "    xs, ys = [], []\n",
        "    for _ in range(epochs):\n",
        "        xs.append(x)\n",
        "        ys.append(f(x))\n",
        "        grad = df(x) + weight_decay * x  # Add weight decay to the gradient\n",
        "        x -= learning_rate * grad\n",
        "    return xs, ys"
      ],
      "metadata": {
        "id": "XlLFbQSsE0m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "initial_x = 1.2  # Starting point, experiment with different values\n",
        "learning_rate = XX\n",
        "epochs = XX\n",
        "weight_decay = 0  # Change to 0.01 or other values to turn on weight decay\n",
        "\n",
        "# Perform gradient descent\n",
        "xs, ys = gradient_descent(initial_x, learning_rate, epochs, weight_decay)"
      ],
      "metadata": {
        "id": "KyHu5kV6E13R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "x_range = np.linspace(-2*np.pi, 2*np.pi, 400)\n",
        "y_range = f(x_range)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(x_range, y_range, label='Error Surface')\n",
        "plt.scatter(xs, ys, color='red', zorder=5, label='SGD Steps')\n",
        "for i, (x, y) in enumerate(zip(xs, ys)):\n",
        "    plt.annotate(str(i), (x, y), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "plt.title(f'SGD Steps on a Complex Error Surface, Last Error: {ys[-1]:.4f}')\n",
        "plt.xlabel('Parameter Value')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "diQ7ChjSE3NS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}